{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Galaxy_Resnet50_Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "abf8191cef6c4c9b83711b8dc95c3bf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b52babcb085e4ba39cd6842d5093e1a3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5aa2076999f4436cb3e1ee81346bc275",
              "IPY_MODEL_d8fe88812f6949de9e00a249d69bbaee",
              "IPY_MODEL_e6105af150fa4819a24538b7913ef794"
            ]
          }
        },
        "b52babcb085e4ba39cd6842d5093e1a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5aa2076999f4436cb3e1ee81346bc275": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_675cddeb004645c1a67c56a06538fd1a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_93054242287e47179e5f627060498b2d"
          }
        },
        "d8fe88812f6949de9e00a249d69bbaee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0a925460c3aa4a6bb1f13fe1033c8a48",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102530333,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102530333,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_38aab35daccc4e3cbbb6f04fb972b5cb"
          }
        },
        "e6105af150fa4819a24538b7913ef794": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_863ff3480c394188b3c7881bbd0d54fb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [00:00&lt;00:00, 178MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dcbca4932bee4672a4ca38156f09149b"
          }
        },
        "675cddeb004645c1a67c56a06538fd1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "93054242287e47179e5f627060498b2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0a925460c3aa4a6bb1f13fe1033c8a48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "38aab35daccc4e3cbbb6f04fb972b5cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "863ff3480c394188b3c7881bbd0d54fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dcbca4932bee4672a4ca38156f09149b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yifo65KNoWXT"
      },
      "source": [
        "# Galaxy Classification with CNN (Pytorch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5S56vHLe3c3"
      },
      "source": [
        "Data:\n",
        "\n",
        "https://www.kaggle.com/c/galaxy-zoo-the-galaxy-challenge\n",
        "\n",
        "\n",
        "\n",
        "References:\n",
        "\n",
        "1. https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
        "\n",
        "2. https://pytorch.org/vision/stable/models.html\n",
        "\n",
        "3. https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
        "\n",
        "4. https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
        "\n",
        "5. https://cs231n.github.io/transfer-learning/\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fwc85DENonBC"
      },
      "source": [
        "## Check GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZrBahOJopJ0",
        "outputId": "a47b47c6-6768-49c3-ac3b-e7d8357a6a80"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla V100-SXM2-16GB (UUID: GPU-4720d713-366b-ca23-e60e-556af4a2f4c3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlrwVfr4RKQY"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8fsV8Q4qFzZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "292b4b89-08ab-402c-98f9-a9e35a3c072b"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms, utils\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "import time\n",
        "import os\n",
        "import zipfile\n",
        "from copy import deepcopy\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5P4GHgJl3e4F"
      },
      "source": [
        "## Unzip images\n",
        "\n",
        "Before running the code, please upload `images_train.zip`, `images_valid.zip` and `images_test.zip` to the workspace.\n",
        "\n",
        "We upzip these 3 files, and place\"\n",
        "\n",
        "- all training images (n=39,410) into the folder `images_train`\n",
        "- all validation images (n=9,852) into the folder `images_valid`, and\n",
        "- all test images (n=12,316) into the folder `images_test`.\n",
        "\n",
        "We create the folders first if they don't exist."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1EQFLSE26yI"
      },
      "source": [
        "## The unzipping function\n",
        "def unzipping(zip_file_name, dest_dir):\n",
        "    \"\"\"\n",
        "    Arguments\n",
        "        zip_file_name: (str) the file name of the zip file\n",
        "        dest_dir: (str) the name of the destination folder\n",
        "    \"\"\"\n",
        "    # check if the destination folder exists. Create one if not.\n",
        "    if not os.path.exists(dest_dir):\n",
        "        os.makedirs(dest_dir)\n",
        "    \n",
        "    # unzipping\n",
        "    zip_f = zipfile.ZipFile(zip_file_name, 'r')\n",
        "    zip_f.extractall(path=dest_dir)\n",
        "    zip_f.close()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9Wyot693kja"
      },
      "source": [
        "## Unzip training, validation, and test images\n",
        "unzipping('images_train.zip', 'images_train')\n",
        "unzipping('images_valid.zip', 'images_valid')\n",
        "unzipping('images_test.zip', 'images_test')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esHistF0xurq"
      },
      "source": [
        "## Import custom datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEri0qqsKZO7"
      },
      "source": [
        "## Custom Galaxy Zoo Dataset\n",
        "class GalaxyZooDataset(Dataset):\n",
        "    \"\"\"Galaxy Zoo Dataset\"\"\"\n",
        "\n",
        "    def __init__(self, csv_file, images_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): path to the label csv\n",
        "            images_dir (string): path to the dir containing all images\n",
        "            transform (callable, optional): transform to apply\n",
        "        \"\"\"\n",
        "        self.labels_df = pd.read_csv(csv_file)\n",
        "        self.images_dir = images_dir\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the size of the dataset\n",
        "        \"\"\"\n",
        "        return len(self.labels_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Get the idx-th sample.\n",
        "\t\tOutputs the image (channel first) and the true label\n",
        "        \"\"\"\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        \n",
        "        # galaxy ID\n",
        "        galaxyid = self.labels_df.iloc[idx, 0].astype(str)\n",
        "\t\t# path of the image\n",
        "        image_path = os.path.join(self.images_dir, galaxyid + '.jpg')\n",
        "\t\t# read the image\n",
        "        image = Image.open(image_path)\n",
        "\t\t# apply transform (optional)\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\t\t# read the true label\n",
        "        label = int(self.labels_df.iloc[idx, 1])\n",
        "\n",
        "        return image, label"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y08fY_k5qTAw"
      },
      "source": [
        "## Data Augmentation Transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe6kpSYMAfHX"
      },
      "source": [
        "def create_data_transforms(is_for_inception=False):\n",
        "    \"\"\"\n",
        "    Create Pytorch data transforms for the GalaxyZoo datasets.\n",
        "    Args:\n",
        "        is_for_inception (bool): True for inception neural networks\n",
        "    Outputs:\n",
        "        train_transform: transform for the training data\n",
        "        test_transform: transform for the testing data\n",
        "    \"\"\"\n",
        "    if is_for_inception:\n",
        "        input_size = 299\n",
        "    else:\n",
        "        input_size = 224\n",
        "\n",
        "    # transforms for training data\n",
        "    train_transform = transforms.Compose([transforms.CenterCrop(input_size),\n",
        "                                          transforms.RandomRotation(90),\n",
        "                                          transforms.RandomHorizontalFlip(),\n",
        "                                          transforms.RandomVerticalFlip(),\n",
        "                                          transforms.RandomResizedCrop(input_size, scale=(0.8, 1.0), ratio=(0.99, 1.01)),\n",
        "                                          transforms.ToTensor(),\n",
        "                                          transforms.Normalize([0, 0, 0], [255, 255, 255]),\n",
        "                                          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "    # transforms for validation data\n",
        "    valid_transform = transforms.Compose([transforms.CenterCrop(input_size),\n",
        "                                          transforms.RandomRotation(90),\n",
        "                                          transforms.RandomHorizontalFlip(),\n",
        "                                          transforms.RandomVerticalFlip(),\n",
        "                                          transforms.RandomResizedCrop(input_size, scale=(0.8, 1.0), ratio=(0.99, 1.01)),\n",
        "                                          transforms.ToTensor(),\n",
        "                                          transforms.Normalize([0, 0, 0], [255, 255, 255]),\n",
        "                                          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])  \n",
        "\n",
        "    # transforms for test data\n",
        "    test_transform = transforms.Compose([transforms.CenterCrop(input_size),\n",
        "                                         transforms.ToTensor(),\n",
        "                                         transforms.Normalize([0, 0, 0], [255, 255, 255]),\n",
        "                                         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "    \n",
        "    return train_transform, valid_transform, test_transform"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CkHW-whSm1k"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pno9P9QXSoQk"
      },
      "source": [
        "NUM_OF_CLASSES = 5  # there are 5 classes in total\n",
        "BATCH_SIZE = 32     # batch zize"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cz6M8LmPepyX"
      },
      "source": [
        "## Training function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMu7cVh1bEtO"
      },
      "source": [
        "def train_model(model, num_epochs, criterion, optimizer, scheduler, print_every=1, is_for_inception=False):\n",
        "    \"\"\"\n",
        "    Train the model\n",
        "    Args:\n",
        "        model: Pytorch neural model\n",
        "        num_epochs: number of epochs to train\n",
        "        criterion: the loss function object\n",
        "        optimizer: the optimizer\n",
        "        scheduler: the learning rate decay scheduler\n",
        "        print_every: print the information every X epochs\n",
        "        is_for_inception: True if the model is an inception model\n",
        "    \"\"\"\n",
        "    # cache the best model\n",
        "    best_model_weights = deepcopy(model.state_dict())\n",
        "    # best valid acc\n",
        "    best_valid_acc = 0.0\n",
        "    # best epoch\n",
        "    best_epoch = -1\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # time of start\n",
        "        epoch_start_time = time.time()\n",
        "\n",
        "        \"\"\"\n",
        "        Train\n",
        "        \"\"\"\n",
        "        model.train()\n",
        "\n",
        "        epoch_train_cum_loss = 0.0\n",
        "        epoch_train_cum_corrects = 0\n",
        "        \n",
        "        for images, labels in train_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.long().to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            if is_for_inception:\n",
        "                pred_logits, aux_outputs = model(images)\n",
        "                loss = criterion(pred_logits, labels) + 0.4*criterion(aux_outputs, labels)\n",
        "            else:\n",
        "                pred_logits = model(images)\n",
        "                loss = criterion(pred_logits, labels)\n",
        "\n",
        "            _, pred_classes = torch.max(pred_logits.detach(), dim=1)\n",
        "            pred_classes = pred_classes.long()\n",
        "\n",
        "            epoch_train_cum_loss += loss.item() * images.size(0)\n",
        "            epoch_train_cum_corrects += torch.sum(pred_classes==labels.data)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "        \"\"\"\n",
        "        Eval\n",
        "        \"\"\"\n",
        "        model.eval()\n",
        "\n",
        "        epoch_valid_cum_loss = 0.0\n",
        "        epoch_valid_cum_corrects = 0\n",
        "\n",
        "        for images, labels in valid_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.long().to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                pred_logits = model(images)\n",
        "                _, pred_classes = torch.max(pred_logits.detach(), dim=1)\n",
        "                loss = criterion(pred_logits, labels)\n",
        "\n",
        "                epoch_valid_cum_loss += loss.item() * images.size(0)\n",
        "                epoch_valid_cum_corrects += torch.sum(pred_classes==labels.data)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        ## Calculate metrics\n",
        "        train_loss = epoch_train_cum_loss / len(data_train)\n",
        "        train_acc = epoch_train_cum_corrects / len(data_train)\n",
        "        valid_loss = epoch_valid_cum_loss / len(data_valid)\n",
        "        valid_acc = epoch_valid_cum_corrects / len(data_valid)\n",
        "\n",
        "        # check if is the best acc ever\n",
        "        if valid_acc > best_valid_acc:\n",
        "            best_valid_acc = valid_acc\n",
        "            best_epoch = epoch + 1\n",
        "            # update the best model weights\n",
        "            best_model_weights = deepcopy(model.state_dict())\n",
        "\n",
        "        \n",
        "        epoch_end_time = time.time()\n",
        "        epoch_time_used = epoch_end_time - epoch_start_time\n",
        "\n",
        "        ## Print metrics\n",
        "        if (epoch+1) % print_every == 0:\n",
        "            print(\"Epoch {}/{}\\tTrain loss: {:.4f}\\tTrain acc: {:.3f}\\tValid loss: {:.4f}\\tValid acc: {:.3f}\\tTime: {:.0f}m {:.0f}s\".format(\n",
        "                epoch+1, num_epochs, train_loss, train_acc, valid_loss, valid_acc, epoch_time_used // 60, epoch_time_used % 60))\n",
        "    \n",
        "    # load the best weights into the model\n",
        "    model.load_state_dict(best_model_weights)\n",
        "    # print the best epoch\n",
        "    print(\"Best epoch = {}, with acc = {:.3f}\".format(best_epoch, best_valid_acc))\n",
        "    # return the best model\n",
        "    return model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Old_Wbz6OAO8"
      },
      "source": [
        "## ResNet50 Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtooFp-SOW9r"
      },
      "source": [
        "### Model architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "abf8191cef6c4c9b83711b8dc95c3bf7",
            "b52babcb085e4ba39cd6842d5093e1a3",
            "5aa2076999f4436cb3e1ee81346bc275",
            "d8fe88812f6949de9e00a249d69bbaee",
            "e6105af150fa4819a24538b7913ef794",
            "675cddeb004645c1a67c56a06538fd1a",
            "93054242287e47179e5f627060498b2d",
            "0a925460c3aa4a6bb1f13fe1033c8a48",
            "38aab35daccc4e3cbbb6f04fb972b5cb",
            "863ff3480c394188b3c7881bbd0d54fb",
            "dcbca4932bee4672a4ca38156f09149b"
          ]
        },
        "id": "CfrvERMWOCrF",
        "outputId": "764de758-1de9-4ad6-ca92-28b8871f3eb4"
      },
      "source": [
        "## Resnet50 architecture\n",
        "model = models.resnet50(pretrained=True)\n",
        "print(model)\n",
        "# count trainable parameters\n",
        "print(\"==========\")\n",
        "print(\"Number of trainable parameters:\")\n",
        "print(\"layer1: {}\".format(sum(param.numel() for param in model.layer1.parameters() if param.requires_grad)))\n",
        "print(\"layer2: {}\".format(sum(param.numel() for param in model.layer2.parameters() if param.requires_grad)))\n",
        "print(\"layer3: {}\".format(sum(param.numel() for param in model.layer3.parameters() if param.requires_grad)))\n",
        "print(\"layer4: {}\".format(sum(param.numel() for param in model.layer4.parameters() if param.requires_grad)))\n",
        "print(\"fc: {}\".format(sum(param.numel() for param in model.fc.parameters() if param.requires_grad)))\n",
        "print(\"TOTAL: {}\".format(sum(param.numel() for param in model.parameters() if param.requires_grad)))\n",
        "print(\"==========\")\n",
        "# free the space\n",
        "del model"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abf8191cef6c4c9b83711b8dc95c3bf7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            ")\n",
            "==========\n",
            "Number of trainable parameters:\n",
            "layer1: 215808\n",
            "layer2: 1219584\n",
            "layer3: 7098368\n",
            "layer4: 14964736\n",
            "fc: 2049000\n",
            "TOTAL: 25557032\n",
            "==========\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oY7PN4p2SiI"
      },
      "source": [
        "### Create transforms and dataloaders\n",
        "\n",
        "We set `is_for_inception` to `False`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7U4-obC2MZl",
        "outputId": "321dea28-c4eb-446d-910f-39429c67207f"
      },
      "source": [
        "# create transforms\n",
        "train_transform, valid_transform, test_transform = create_data_transforms(is_for_inception=False)\n",
        "\n",
        "# create datasets\n",
        "data_train = GalaxyZooDataset('labels_train.csv', 'images_train', train_transform)\n",
        "data_valid = GalaxyZooDataset('labels_valid.csv', 'images_valid', valid_transform)\n",
        "data_test = GalaxyZooDataset('labels_test.csv', 'images_test', test_transform)\n",
        "\n",
        "# dataloaders\n",
        "train_loader = DataLoader(data_train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "valid_loader = DataLoader(data_valid, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(data_test, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# check the sizes\n",
        "print(\"Number of training data: {} ({} batches)\".format(len(data_train), len(train_loader)))\n",
        "print(\"Number of validation data: {} ({} batches)\".format(len(data_valid), len(valid_loader)))\n",
        "print(\"Number of test data: {} ({} batches)\".format(len(data_test), len(test_loader)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training data: 39410 (1232 batches)\n",
            "Number of validation data: 9852 (308 batches)\n",
            "Number of test data: 12316 (385 batches)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkfVGAy12eU5"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6wMO6dX2fsZ",
        "outputId": "e4cabf9e-12ea-4779-d7e0-9dae83450ce3"
      },
      "source": [
        "## Download the pre-trained resnet50 model\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# change the last fc layer\n",
        "model.fc = nn.Linear(2048, NUM_OF_CLASSES)\n",
        "print(model.fc) # print the modified last layer\n",
        "\n",
        "print(\"============\")\n",
        "print(\"Training\")\n",
        "print(\"Number of trainable parameters: {}\".format(sum(param.numel() for param in model.parameters() if param.requires_grad)))\n",
        "print(\"============\")\n",
        "\n",
        "# move to gpu\n",
        "model = model.to(device)\n",
        "# loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "# scheduler\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
        "\n",
        "## train and return the best model\n",
        "model = train_model(model, 100, criterion, optimizer, scheduler, print_every=1, is_for_inception=False)\n",
        "\n",
        "## Save the best weights\n",
        "torch.save(model.state_dict(), 'resnet50_trained.pth')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear(in_features=2048, out_features=5, bias=True)\n",
            "============\n",
            "Training\n",
            "Number of trainable parameters: 23518277\n",
            "============\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\tTrain loss: 0.8254\tTrain acc: 0.684\tValid loss: 3.0218\tValid acc: 0.590\tTime: 6m 16s\n",
            "Epoch 2/100\tTrain loss: 0.6896\tTrain acc: 0.733\tValid loss: 15.0500\tValid acc: 0.057\tTime: 6m 14s\n",
            "Epoch 3/100\tTrain loss: 0.6438\tTrain acc: 0.749\tValid loss: 9.8982\tValid acc: 0.089\tTime: 6m 14s\n",
            "Epoch 4/100\tTrain loss: 0.6174\tTrain acc: 0.761\tValid loss: 7.9740\tValid acc: 0.057\tTime: 6m 14s\n",
            "Epoch 5/100\tTrain loss: 0.5918\tTrain acc: 0.770\tValid loss: 1.2454\tValid acc: 0.454\tTime: 6m 14s\n",
            "Epoch 6/100\tTrain loss: 0.5752\tTrain acc: 0.773\tValid loss: 10.9958\tValid acc: 0.089\tTime: 6m 15s\n",
            "Epoch 7/100\tTrain loss: 0.5623\tTrain acc: 0.779\tValid loss: 1.3095\tValid acc: 0.467\tTime: 6m 14s\n",
            "Epoch 8/100\tTrain loss: 0.5509\tTrain acc: 0.782\tValid loss: 1.9780\tValid acc: 0.264\tTime: 6m 14s\n",
            "Epoch 9/100\tTrain loss: 0.5423\tTrain acc: 0.788\tValid loss: 1.7393\tValid acc: 0.194\tTime: 6m 15s\n",
            "Epoch 10/100\tTrain loss: 0.5305\tTrain acc: 0.791\tValid loss: 3.2972\tValid acc: 0.094\tTime: 6m 15s\n",
            "Epoch 11/100\tTrain loss: 0.5212\tTrain acc: 0.793\tValid loss: 1.3574\tValid acc: 0.469\tTime: 6m 16s\n",
            "Epoch 12/100\tTrain loss: 0.5150\tTrain acc: 0.797\tValid loss: 0.9536\tValid acc: 0.594\tTime: 6m 12s\n",
            "Epoch 13/100\tTrain loss: 0.5045\tTrain acc: 0.801\tValid loss: 2.5641\tValid acc: 0.077\tTime: 6m 12s\n",
            "Epoch 14/100\tTrain loss: 0.5004\tTrain acc: 0.802\tValid loss: 19.7645\tValid acc: 0.000\tTime: 6m 11s\n",
            "Epoch 15/100\tTrain loss: 0.4959\tTrain acc: 0.803\tValid loss: 2.7560\tValid acc: 0.254\tTime: 6m 12s\n",
            "Epoch 16/100\tTrain loss: 0.4894\tTrain acc: 0.806\tValid loss: 22.7946\tValid acc: 0.057\tTime: 6m 12s\n",
            "Epoch 17/100\tTrain loss: 0.4842\tTrain acc: 0.807\tValid loss: 2.8079\tValid acc: 0.127\tTime: 6m 12s\n",
            "Epoch 18/100\tTrain loss: 0.4784\tTrain acc: 0.810\tValid loss: 0.5963\tValid acc: 0.767\tTime: 6m 11s\n",
            "Epoch 19/100\tTrain loss: 0.4749\tTrain acc: 0.811\tValid loss: 1.6764\tValid acc: 0.272\tTime: 6m 13s\n",
            "Epoch 20/100\tTrain loss: 0.4705\tTrain acc: 0.814\tValid loss: 1.3352\tValid acc: 0.431\tTime: 6m 13s\n",
            "Epoch 21/100\tTrain loss: 0.4671\tTrain acc: 0.814\tValid loss: 2.0173\tValid acc: 0.163\tTime: 6m 13s\n",
            "Epoch 22/100\tTrain loss: 0.4653\tTrain acc: 0.815\tValid loss: 9.9972\tValid acc: 0.020\tTime: 6m 13s\n",
            "Epoch 23/100\tTrain loss: 0.4626\tTrain acc: 0.816\tValid loss: 11.2662\tValid acc: 0.039\tTime: 6m 14s\n",
            "Epoch 24/100\tTrain loss: 0.4581\tTrain acc: 0.818\tValid loss: 2.6687\tValid acc: 0.200\tTime: 6m 13s\n",
            "Epoch 25/100\tTrain loss: 0.4555\tTrain acc: 0.819\tValid loss: 0.9282\tValid acc: 0.618\tTime: 6m 14s\n",
            "Epoch 26/100\tTrain loss: 0.4527\tTrain acc: 0.819\tValid loss: 7.6045\tValid acc: 0.061\tTime: 6m 14s\n",
            "Epoch 27/100\tTrain loss: 0.4503\tTrain acc: 0.821\tValid loss: 1.3093\tValid acc: 0.522\tTime: 6m 15s\n",
            "Epoch 28/100\tTrain loss: 0.4491\tTrain acc: 0.823\tValid loss: 1.2158\tValid acc: 0.461\tTime: 6m 15s\n",
            "Epoch 29/100\tTrain loss: 0.4489\tTrain acc: 0.822\tValid loss: 6.3663\tValid acc: 0.069\tTime: 6m 14s\n",
            "Epoch 30/100\tTrain loss: 0.4444\tTrain acc: 0.823\tValid loss: 2.1412\tValid acc: 0.259\tTime: 6m 14s\n",
            "Epoch 31/100\tTrain loss: 0.4441\tTrain acc: 0.822\tValid loss: 0.5734\tValid acc: 0.773\tTime: 6m 14s\n",
            "Epoch 32/100\tTrain loss: 0.4421\tTrain acc: 0.823\tValid loss: 1.6842\tValid acc: 0.445\tTime: 6m 13s\n",
            "Epoch 33/100\tTrain loss: 0.4400\tTrain acc: 0.824\tValid loss: 1.1569\tValid acc: 0.497\tTime: 6m 14s\n",
            "Epoch 34/100\tTrain loss: 0.4398\tTrain acc: 0.824\tValid loss: 4.5902\tValid acc: 0.132\tTime: 6m 14s\n",
            "Epoch 35/100\tTrain loss: 0.4380\tTrain acc: 0.825\tValid loss: 0.5582\tValid acc: 0.784\tTime: 6m 14s\n",
            "Epoch 36/100\tTrain loss: 0.4368\tTrain acc: 0.825\tValid loss: 0.6540\tValid acc: 0.736\tTime: 6m 14s\n",
            "Epoch 37/100\tTrain loss: 0.4371\tTrain acc: 0.825\tValid loss: 1.3138\tValid acc: 0.535\tTime: 6m 14s\n",
            "Epoch 38/100\tTrain loss: 0.4361\tTrain acc: 0.826\tValid loss: 1.4741\tValid acc: 0.371\tTime: 6m 14s\n",
            "Epoch 39/100\tTrain loss: 0.4325\tTrain acc: 0.827\tValid loss: 1.7461\tValid acc: 0.401\tTime: 6m 14s\n",
            "Epoch 40/100\tTrain loss: 0.4322\tTrain acc: 0.827\tValid loss: 0.6921\tValid acc: 0.723\tTime: 6m 14s\n",
            "Epoch 41/100\tTrain loss: 0.4326\tTrain acc: 0.826\tValid loss: 0.5606\tValid acc: 0.785\tTime: 6m 14s\n",
            "Epoch 42/100\tTrain loss: 0.4319\tTrain acc: 0.826\tValid loss: 0.5003\tValid acc: 0.805\tTime: 6m 14s\n",
            "Epoch 43/100\tTrain loss: 0.4304\tTrain acc: 0.829\tValid loss: 0.5627\tValid acc: 0.778\tTime: 6m 13s\n",
            "Epoch 44/100\tTrain loss: 0.4301\tTrain acc: 0.829\tValid loss: 0.5066\tValid acc: 0.803\tTime: 6m 13s\n",
            "Epoch 45/100\tTrain loss: 0.4297\tTrain acc: 0.828\tValid loss: 0.6630\tValid acc: 0.716\tTime: 6m 14s\n",
            "Epoch 46/100\tTrain loss: 0.4303\tTrain acc: 0.828\tValid loss: 0.4826\tValid acc: 0.812\tTime: 6m 13s\n",
            "Epoch 47/100\tTrain loss: 0.4283\tTrain acc: 0.829\tValid loss: 0.4936\tValid acc: 0.807\tTime: 6m 13s\n",
            "Epoch 48/100\tTrain loss: 0.4290\tTrain acc: 0.829\tValid loss: 0.4863\tValid acc: 0.809\tTime: 6m 13s\n",
            "Epoch 49/100\tTrain loss: 0.4289\tTrain acc: 0.829\tValid loss: 0.5110\tValid acc: 0.794\tTime: 6m 14s\n",
            "Epoch 50/100\tTrain loss: 0.4289\tTrain acc: 0.829\tValid loss: 0.5208\tValid acc: 0.789\tTime: 6m 13s\n",
            "Epoch 51/100\tTrain loss: 0.4274\tTrain acc: 0.830\tValid loss: 0.4784\tValid acc: 0.809\tTime: 6m 14s\n",
            "Epoch 52/100\tTrain loss: 0.4269\tTrain acc: 0.830\tValid loss: 0.4833\tValid acc: 0.809\tTime: 6m 13s\n",
            "Epoch 53/100\tTrain loss: 0.4280\tTrain acc: 0.830\tValid loss: 0.4842\tValid acc: 0.810\tTime: 6m 15s\n",
            "Epoch 54/100\tTrain loss: 0.4285\tTrain acc: 0.830\tValid loss: 0.4839\tValid acc: 0.809\tTime: 6m 14s\n",
            "Epoch 55/100\tTrain loss: 0.4271\tTrain acc: 0.829\tValid loss: 0.4816\tValid acc: 0.807\tTime: 6m 14s\n",
            "Epoch 56/100\tTrain loss: 0.4273\tTrain acc: 0.829\tValid loss: 0.4820\tValid acc: 0.810\tTime: 6m 13s\n",
            "Epoch 57/100\tTrain loss: 0.4263\tTrain acc: 0.828\tValid loss: 0.4857\tValid acc: 0.807\tTime: 6m 11s\n",
            "Epoch 58/100\tTrain loss: 0.4269\tTrain acc: 0.830\tValid loss: 0.4752\tValid acc: 0.813\tTime: 6m 13s\n",
            "Epoch 59/100\tTrain loss: 0.4256\tTrain acc: 0.832\tValid loss: 0.4831\tValid acc: 0.809\tTime: 6m 12s\n",
            "Epoch 60/100\tTrain loss: 0.4265\tTrain acc: 0.829\tValid loss: 0.4871\tValid acc: 0.808\tTime: 6m 10s\n",
            "Epoch 61/100\tTrain loss: 0.4271\tTrain acc: 0.830\tValid loss: 0.4799\tValid acc: 0.809\tTime: 6m 12s\n",
            "Epoch 62/100\tTrain loss: 0.4265\tTrain acc: 0.831\tValid loss: 0.4845\tValid acc: 0.809\tTime: 6m 11s\n",
            "Epoch 63/100\tTrain loss: 0.4257\tTrain acc: 0.830\tValid loss: 0.4790\tValid acc: 0.811\tTime: 6m 11s\n",
            "Epoch 64/100\tTrain loss: 0.4268\tTrain acc: 0.830\tValid loss: 0.4796\tValid acc: 0.807\tTime: 6m 11s\n",
            "Epoch 65/100\tTrain loss: 0.4256\tTrain acc: 0.829\tValid loss: 0.4816\tValid acc: 0.808\tTime: 6m 11s\n",
            "Epoch 66/100\tTrain loss: 0.4264\tTrain acc: 0.829\tValid loss: 0.4818\tValid acc: 0.812\tTime: 6m 11s\n",
            "Epoch 67/100\tTrain loss: 0.4264\tTrain acc: 0.830\tValid loss: 0.4762\tValid acc: 0.812\tTime: 6m 11s\n",
            "Epoch 68/100\tTrain loss: 0.4273\tTrain acc: 0.829\tValid loss: 0.4804\tValid acc: 0.809\tTime: 6m 13s\n",
            "Epoch 69/100\tTrain loss: 0.4261\tTrain acc: 0.830\tValid loss: 0.4817\tValid acc: 0.810\tTime: 6m 16s\n",
            "Epoch 70/100\tTrain loss: 0.4261\tTrain acc: 0.830\tValid loss: 0.4808\tValid acc: 0.810\tTime: 6m 17s\n",
            "Epoch 71/100\tTrain loss: 0.4264\tTrain acc: 0.830\tValid loss: 0.4816\tValid acc: 0.810\tTime: 6m 15s\n",
            "Epoch 72/100\tTrain loss: 0.4242\tTrain acc: 0.831\tValid loss: 0.4755\tValid acc: 0.809\tTime: 6m 14s\n",
            "Epoch 73/100\tTrain loss: 0.4249\tTrain acc: 0.831\tValid loss: 0.4813\tValid acc: 0.810\tTime: 6m 13s\n",
            "Epoch 74/100\tTrain loss: 0.4249\tTrain acc: 0.831\tValid loss: 0.4794\tValid acc: 0.810\tTime: 6m 12s\n",
            "Epoch 75/100\tTrain loss: 0.4274\tTrain acc: 0.829\tValid loss: 0.4769\tValid acc: 0.811\tTime: 6m 14s\n",
            "Epoch 76/100\tTrain loss: 0.4256\tTrain acc: 0.830\tValid loss: 0.4825\tValid acc: 0.809\tTime: 6m 13s\n",
            "Epoch 77/100\tTrain loss: 0.4241\tTrain acc: 0.832\tValid loss: 0.4815\tValid acc: 0.810\tTime: 6m 13s\n",
            "Epoch 78/100\tTrain loss: 0.4271\tTrain acc: 0.831\tValid loss: 0.4827\tValid acc: 0.811\tTime: 6m 14s\n",
            "Epoch 79/100\tTrain loss: 0.4257\tTrain acc: 0.830\tValid loss: 0.4811\tValid acc: 0.811\tTime: 6m 14s\n",
            "Epoch 80/100\tTrain loss: 0.4244\tTrain acc: 0.830\tValid loss: 0.4769\tValid acc: 0.813\tTime: 6m 13s\n",
            "Epoch 81/100\tTrain loss: 0.4266\tTrain acc: 0.828\tValid loss: 0.4819\tValid acc: 0.809\tTime: 6m 12s\n",
            "Epoch 82/100\tTrain loss: 0.4244\tTrain acc: 0.832\tValid loss: 0.4759\tValid acc: 0.810\tTime: 6m 12s\n",
            "Epoch 83/100\tTrain loss: 0.4259\tTrain acc: 0.831\tValid loss: 0.4778\tValid acc: 0.811\tTime: 6m 11s\n",
            "Epoch 84/100\tTrain loss: 0.4254\tTrain acc: 0.830\tValid loss: 0.4782\tValid acc: 0.812\tTime: 6m 11s\n",
            "Epoch 85/100\tTrain loss: 0.4248\tTrain acc: 0.829\tValid loss: 0.4792\tValid acc: 0.811\tTime: 6m 13s\n",
            "Epoch 86/100\tTrain loss: 0.4259\tTrain acc: 0.830\tValid loss: 0.4805\tValid acc: 0.810\tTime: 6m 12s\n",
            "Epoch 87/100\tTrain loss: 0.4257\tTrain acc: 0.831\tValid loss: 0.4800\tValid acc: 0.810\tTime: 6m 13s\n",
            "Epoch 88/100\tTrain loss: 0.4235\tTrain acc: 0.831\tValid loss: 0.4802\tValid acc: 0.812\tTime: 6m 13s\n",
            "Epoch 89/100\tTrain loss: 0.4249\tTrain acc: 0.831\tValid loss: 0.4820\tValid acc: 0.812\tTime: 6m 13s\n",
            "Epoch 90/100\tTrain loss: 0.4262\tTrain acc: 0.831\tValid loss: 0.4787\tValid acc: 0.811\tTime: 6m 12s\n",
            "Epoch 91/100\tTrain loss: 0.4255\tTrain acc: 0.830\tValid loss: 0.4799\tValid acc: 0.810\tTime: 6m 11s\n",
            "Epoch 92/100\tTrain loss: 0.4259\tTrain acc: 0.830\tValid loss: 0.4815\tValid acc: 0.810\tTime: 6m 10s\n",
            "Epoch 93/100\tTrain loss: 0.4255\tTrain acc: 0.830\tValid loss: 0.4800\tValid acc: 0.810\tTime: 6m 10s\n",
            "Epoch 94/100\tTrain loss: 0.4248\tTrain acc: 0.829\tValid loss: 0.4786\tValid acc: 0.813\tTime: 6m 11s\n",
            "Epoch 95/100\tTrain loss: 0.4257\tTrain acc: 0.831\tValid loss: 0.4802\tValid acc: 0.808\tTime: 6m 11s\n",
            "Epoch 96/100\tTrain loss: 0.4249\tTrain acc: 0.829\tValid loss: 0.4811\tValid acc: 0.811\tTime: 6m 13s\n",
            "Epoch 97/100\tTrain loss: 0.4257\tTrain acc: 0.830\tValid loss: 0.4820\tValid acc: 0.809\tTime: 6m 12s\n",
            "Epoch 98/100\tTrain loss: 0.4253\tTrain acc: 0.829\tValid loss: 0.4800\tValid acc: 0.809\tTime: 6m 11s\n",
            "Epoch 99/100\tTrain loss: 0.4246\tTrain acc: 0.832\tValid loss: 0.4777\tValid acc: 0.810\tTime: 6m 11s\n",
            "Epoch 100/100\tTrain loss: 0.4248\tTrain acc: 0.830\tValid loss: 0.4814\tValid acc: 0.808\tTime: 6m 12s\n",
            "Best epoch = 58, with acc = 0.813\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNtQHg4N0PD8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}