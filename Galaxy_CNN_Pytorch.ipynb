{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Galaxy_CNN_Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "def49d2d3caa4f6489614e80703a87dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3de3c6bcff0c4294b62e3af4435ba06e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6286349560a44eec84827a53de9a8dd0",
              "IPY_MODEL_d69676d8ca824584aa947b29be0aeb98",
              "IPY_MODEL_c5cfef01062d4a98adce302099c45e4d"
            ]
          }
        },
        "3de3c6bcff0c4294b62e3af4435ba06e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6286349560a44eec84827a53de9a8dd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d789aef464a74ea880669381dde042ad",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c25b3a3a17624d018c2ec01f8713f13d"
          }
        },
        "d69676d8ca824584aa947b29be0aeb98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_79f9026d2c5f470f8f42c9516330543e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 553507836,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 553507836,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_37a92a7709fc4c23a2bb8085f440a20a"
          }
        },
        "c5cfef01062d4a98adce302099c45e4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e8c40fee5ca94a189b7f292946315995",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 528M/528M [00:03&lt;00:00, 194MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_936e1ed817014b5798a6da06b2cc4704"
          }
        },
        "d789aef464a74ea880669381dde042ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c25b3a3a17624d018c2ec01f8713f13d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "79f9026d2c5f470f8f42c9516330543e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "37a92a7709fc4c23a2bb8085f440a20a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e8c40fee5ca94a189b7f292946315995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "936e1ed817014b5798a6da06b2cc4704": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yifo65KNoWXT"
      },
      "source": [
        "# Galaxy Classification with CNN (Pytorch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5S56vHLe3c3"
      },
      "source": [
        "Data:\n",
        "\n",
        "https://www.kaggle.com/c/galaxy-zoo-the-galaxy-challenge\n",
        "\n",
        "\n",
        "\n",
        "References:\n",
        "\n",
        "1. https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
        "\n",
        "2. https://pytorch.org/vision/stable/models.html\n",
        "\n",
        "3. https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
        "\n",
        "4. https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
        "\n",
        "5. https://cs231n.github.io/transfer-learning/\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fwc85DENonBC"
      },
      "source": [
        "## Check GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZrBahOJopJ0",
        "outputId": "d84fe011-9e55-442b-f70d-0737c0e772c9"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-5d99ad53-86af-b254-cd15-29cb277ee66e)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlrwVfr4RKQY"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8fsV8Q4qFzZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6030c83-de27-4f60-d72e-e7dcfd80703f"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms, utils\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "import time\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5P4GHgJl3e4F"
      },
      "source": [
        "## Unzip images\n",
        "\n",
        "Before running the code, please upload `train_46183.zip` and `test_15395.zip` to the workspace.\n",
        "\n",
        "We upzip these 2 files, and place all training images (46,183 images) into the folder `images_train`, and all test images (15,395 images) into the folder `images_test`.\n",
        "\n",
        "We create the folders if they don't exist."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF-3G51t3i_k"
      },
      "source": [
        "## Unzip training images\n",
        "train_dir = 'images_train'\n",
        "# create dir if not exist\n",
        "if not os.path.exists(train_dir):\n",
        "    os.makedirs(train_dir)\n",
        "\n",
        "zip_ref = zipfile.ZipFile('train_46183.zip', 'r')\n",
        "zip_ref.extractall(path=train_dir) # unzip\n",
        "zip_ref.close()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SO0P6HWVo8G8"
      },
      "source": [
        "## Unzip test images\n",
        "test_dir = 'images_test'\n",
        "# create dir if not exist\n",
        "if not os.path.exists(test_dir):\n",
        "    os.makedirs(test_dir)\n",
        "\n",
        "zip_ref = zipfile.ZipFile('test_15395.zip', 'r')\n",
        "zip_ref.extractall(path=test_dir) # unzip\n",
        "zip_ref.close()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esHistF0xurq"
      },
      "source": [
        "## Import custom datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEri0qqsKZO7"
      },
      "source": [
        "## Custom Galaxy Zoo Dataset\n",
        "class GalaxyZooDataset(Dataset):\n",
        "    \"\"\"Galaxy Zoo Dataset\"\"\"\n",
        "\n",
        "    def __init__(self, csv_file, images_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): path to the label csv\n",
        "            images_dir (string): path to the dir containing all images\n",
        "            transform (callable, optional): transform to apply\n",
        "        \"\"\"\n",
        "        self.labels_df = pd.read_csv(csv_file)\n",
        "        self.images_dir = images_dir\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the size of the dataset\n",
        "        \"\"\"\n",
        "        return len(self.labels_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Get the idx-th sample.\n",
        "\t\tOutputs the image (channel first) and the true label\n",
        "        \"\"\"\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        \n",
        "        # galaxy ID\n",
        "        galaxyid = self.labels_df.iloc[idx, 0].astype(str)\n",
        "\t\t# path of the image\n",
        "        image_path = os.path.join(self.images_dir, galaxyid + '.jpg')\n",
        "\t\t# read the image\n",
        "        image = Image.open(image_path)\n",
        "\t\t# apply transform (optional)\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\t\t# read the true label\n",
        "        label = int(self.labels_df.iloc[idx, 1])\n",
        "\n",
        "        return image, label"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y08fY_k5qTAw"
      },
      "source": [
        "## Data Augmentation Transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe6kpSYMAfHX"
      },
      "source": [
        "def create_data_transforms(is_for_inception=False):\n",
        "    \"\"\"\n",
        "    Create Pytorch data transforms for the GalaxyZoo datasets.\n",
        "    Args:\n",
        "        is_for_inception (bool): True for inception neural networks\n",
        "    Outputs:\n",
        "        train_transform: transform for the training data\n",
        "        test_transform: transform for the testing data\n",
        "    \"\"\"\n",
        "    if is_for_inception:\n",
        "        input_size = 299\n",
        "    else:\n",
        "        input_size = 224\n",
        "\n",
        "    train_transform = transforms.Compose([transforms.Resize((input_size, input_size)),\n",
        "                                            transforms.RandomResizedCrop(input_size, scale=(0.8, 1.0), ratio=(0.999, 1.001)),\n",
        "                                            transforms.RandomHorizontalFlip(),\n",
        "                                            transforms.RandomVerticalFlip(),\n",
        "                                            transforms.ToTensor(),\n",
        "                                            transforms.Normalize([0, 0, 0], [255, 255, 255]),\n",
        "                                            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "    test_transform = transforms.Compose([transforms.Resize((input_size, input_size)),\n",
        "                                            transforms.ToTensor(),\n",
        "                                            transforms.Normalize([0, 0, 0], [255, 255, 255]),\n",
        "                                            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "    \n",
        "    return train_transform, test_transform"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CkHW-whSm1k"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pno9P9QXSoQk"
      },
      "source": [
        "NUM_OF_CLASSES = 5  # there are 5 classes in total\n",
        "BATCH_SIZE = 32     # batch zize"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cz6M8LmPepyX"
      },
      "source": [
        "## Training function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMu7cVh1bEtO"
      },
      "source": [
        "def train_model(model, num_epochs, criterion, optimizer, scheduler, print_every=1, is_for_inception=False):\n",
        "    \"\"\"\n",
        "    Train the model\n",
        "    Args:\n",
        "        model: Pytorch neural model\n",
        "        num_epochs: number of epochs to train\n",
        "        criterion: the loss function object\n",
        "        optimizer: the optimizer\n",
        "        scheduler: the learning rate decay scheduler\n",
        "        print_every: print the information every X epochs\n",
        "        is_for_inception: True if the model is an inception model\n",
        "    \"\"\"\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        # time of start\n",
        "        epoch_start_time = time.time()\n",
        "\n",
        "        \"\"\"\n",
        "        Train\n",
        "        \"\"\"\n",
        "        model.train()\n",
        "\n",
        "        epoch_train_cum_loss = 0.0\n",
        "        epoch_train_cum_corrects = 0\n",
        "        \n",
        "        for images, labels in train_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.long().to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            if is_for_inception:\n",
        "                pred_logits, aux_outputs = model(images)\n",
        "                loss = criterion(pred_logits, labels) + 0.4*criterion(aux_outputs, labels)\n",
        "            else:\n",
        "                pred_logits = model(images)\n",
        "                loss = criterion(pred_logits, labels)\n",
        "\n",
        "            _, pred_classes = torch.max(pred_logits.detach(), dim=1)\n",
        "            pred_classes = pred_classes.long()\n",
        "\n",
        "            epoch_train_cum_loss += loss.item() * images.size(0)\n",
        "            epoch_train_cum_corrects += torch.sum(pred_classes==labels.data)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "        \"\"\"\n",
        "        Eval\n",
        "        \"\"\"\n",
        "        model.eval()\n",
        "\n",
        "        epoch_test_cum_loss = 0.0\n",
        "        epoch_test_cum_corrects = 0\n",
        "\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.long().to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                pred_logits = model(images)\n",
        "                _, pred_classes = torch.max(pred_logits.detach(), dim=1)\n",
        "                loss = criterion(pred_logits, labels)\n",
        "\n",
        "                epoch_test_cum_loss += loss.item() * images.size(0)\n",
        "                epoch_test_cum_corrects += torch.sum(pred_classes==labels.data)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        ## Calculate metrics\n",
        "        train_loss = epoch_train_cum_loss / len(data_train)\n",
        "        train_acc = epoch_train_cum_corrects / len(data_train)\n",
        "        test_loss = epoch_test_cum_loss / len(data_test)\n",
        "        test_acc = epoch_test_cum_corrects / len(data_test)\n",
        "        \n",
        "        epoch_end_time = time.time()\n",
        "        epoch_time_used = epoch_end_time - epoch_start_time\n",
        "\n",
        "        ## Print metrics\n",
        "        if (epoch+1) % print_every == 0:\n",
        "            print(\"Epoch {}/{}\\tTrain loss: {:.4f}\\tTrain acc: {:.3f}\\tTest loss: {:.4f}\\tTest acc: {:.3f}\\tTime: {:.0f}m {:.0f}s\".format(\n",
        "                epoch+1, num_epochs, train_loss, train_acc, test_loss, test_acc, epoch_time_used // 60, epoch_time_used % 60))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5lBdXCg_EqU"
      },
      "source": [
        "## ResNet18 Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wd7GWOhFm5Y"
      },
      "source": [
        "### Model architecture\n",
        "\n",
        "**Original paper**\n",
        "\n",
        "Deep Residual Learning for Image Recognition [(arXiv)](https://arxiv.org/abs/1512.03385)\n",
        "\n",
        "**The last layer**\n",
        "\n",
        "The last layer of ResNet18 model is called `fc`, with input size = `512`\n",
        "\n",
        "We replace the last layer with a linear layer by `model.fc = nn.Linear(512, NUM_OF_CLASSES, bias=True)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9VCPZ01ECFB",
        "outputId": "90d12252-eb8a-4569-ba5d-f25a0e8573ad"
      },
      "source": [
        "## Resnet18 architecture\n",
        "model = models.resnet18(pretrained=True)\n",
        "print(model)\n",
        "# count trainable parameters\n",
        "print(\"Number of trainable parameters: {}\".format(sum(param.numel() for param in model.parameters() if param.requires_grad)))\n",
        "# free the space\n",
        "del model"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n",
            "Number of trainable parameters: 11689512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AYNmK1TFc3I"
      },
      "source": [
        "### Create transforms and dataloaders\n",
        "\n",
        "We set `is_for_inception` to `False`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xewezl2iDOmL",
        "outputId": "038ed138-5e83-43e4-c15d-1faf6d583061"
      },
      "source": [
        "# create transform\n",
        "train_transform, test_transform = create_data_transforms(is_for_inception=False)\n",
        "\n",
        "# create dataset\n",
        "data_train = GalaxyZooDataset('class_labels_train_46183_C5.csv', 'images_train', train_transform)\n",
        "data_test = GalaxyZooDataset('class_labels_test_15395_C5.csv', 'images_test', test_transform)\n",
        "\n",
        "# dataloader\n",
        "train_loader = DataLoader(data_train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(data_test, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# check the sizes\n",
        "print(\"Number of training data: {} ({} batches)\".format(len(data_train), len(train_loader)))\n",
        "print(\"Number of testing data: {} ({} batches)\".format(len(data_test), len(test_loader)))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training data: 46183 (1444 batches)\n",
            "Number of testing data: 15395 (482 batches)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQm2hu33FYWY"
      },
      "source": [
        "### Train and fine-tune the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7MxL8Fh_Fpt",
        "outputId": "11a0fb02-b8df-4d6f-adc7-9916632b6cc1"
      },
      "source": [
        "## Download the pre-trained resnet18 model\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# freeze the weights\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# change the last fc layer\n",
        "model.fc = nn.Linear(512, NUM_OF_CLASSES)\n",
        "print(model.fc) # print the modified last layer\n",
        "\n",
        "print(\"============\")\n",
        "print(\"Training the last layer only\")\n",
        "print(\"Number of trainable parameters: {}\".format(sum(param.numel() for param in model.parameters() if param.requires_grad)))\n",
        "print(\"============\")\n",
        "\n",
        "# move to gpu\n",
        "model = model.to(device)\n",
        "# loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "# scheduler\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
        "# train\n",
        "train_model(model, 5, criterion, optimizer, scheduler, print_every=1, is_for_inception=False)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Fine tuning\n",
        "\"\"\"\n",
        "# unfreeze the weights of the last block\n",
        "for param in model.layer4.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "print(\"============\")\n",
        "print(\"Fine Tuning the whole ResNet model\")\n",
        "print(\"Number of trainable parameters: {}\".format(sum(param.numel() for param in model.parameters() if param.requires_grad)))\n",
        "print(\"============\")\n",
        "\n",
        "# move to gpu\n",
        "model = model.to(device)\n",
        "# loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
        "# scheduler\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
        "# train\n",
        "train_model(model, 20, criterion, optimizer, scheduler, print_every=1, is_for_inception=False)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear(in_features=512, out_features=5, bias=True)\n",
            "============\n",
            "Training the last layer only\n",
            "Number of trainable parameters: 2565\n",
            "============\n",
            "Epoch 1/5\tTrain loss: 0.9760\tTrain acc: 0.607\tTest loss: 0.9265\tTest acc: 0.624\tTime: 6m 15s\n",
            "Epoch 2/5\tTrain loss: 0.9462\tTrain acc: 0.613\tTest loss: 0.9789\tTest acc: 0.612\tTime: 6m 15s\n",
            "Epoch 3/5\tTrain loss: 0.9374\tTrain acc: 0.618\tTest loss: 0.9497\tTest acc: 0.629\tTime: 6m 15s\n",
            "Epoch 4/5\tTrain loss: 0.9298\tTrain acc: 0.617\tTest loss: 0.9146\tTest acc: 0.624\tTime: 6m 17s\n",
            "Epoch 5/5\tTrain loss: 0.9222\tTrain acc: 0.620\tTest loss: 0.9305\tTest acc: 0.625\tTime: 6m 20s\n",
            "============\n",
            "Fine Tuning the whole ResNet model\n",
            "Number of trainable parameters: 8396293\n",
            "============\n",
            "Epoch 1/20\tTrain loss: 0.8814\tTrain acc: 0.639\tTest loss: 0.8229\tTest acc: 0.660\tTime: 6m 23s\n",
            "Epoch 2/20\tTrain loss: 0.8334\tTrain acc: 0.658\tTest loss: 0.8372\tTest acc: 0.668\tTime: 6m 23s\n",
            "Epoch 3/20\tTrain loss: 0.8128\tTrain acc: 0.666\tTest loss: 0.7899\tTest acc: 0.672\tTime: 6m 26s\n",
            "Epoch 4/20\tTrain loss: 0.7967\tTrain acc: 0.675\tTest loss: 0.7808\tTest acc: 0.682\tTime: 6m 23s\n",
            "Epoch 5/20\tTrain loss: 0.7884\tTrain acc: 0.678\tTest loss: 0.7882\tTest acc: 0.684\tTime: 6m 22s\n",
            "Epoch 6/20\tTrain loss: 0.7739\tTrain acc: 0.685\tTest loss: 0.7702\tTest acc: 0.682\tTime: 6m 28s\n",
            "Epoch 7/20\tTrain loss: 0.7665\tTrain acc: 0.684\tTest loss: 0.7611\tTest acc: 0.688\tTime: 6m 20s\n",
            "Epoch 8/20\tTrain loss: 0.7595\tTrain acc: 0.689\tTest loss: 0.7626\tTest acc: 0.683\tTime: 6m 23s\n",
            "Epoch 9/20\tTrain loss: 0.7505\tTrain acc: 0.693\tTest loss: 0.7615\tTest acc: 0.682\tTime: 6m 19s\n",
            "Epoch 10/20\tTrain loss: 0.7430\tTrain acc: 0.694\tTest loss: 0.7511\tTest acc: 0.695\tTime: 6m 18s\n",
            "Epoch 11/20\tTrain loss: 0.7369\tTrain acc: 0.699\tTest loss: 0.7490\tTest acc: 0.694\tTime: 6m 19s\n",
            "Epoch 12/20\tTrain loss: 0.7323\tTrain acc: 0.700\tTest loss: 0.7566\tTest acc: 0.688\tTime: 6m 18s\n",
            "Epoch 13/20\tTrain loss: 0.7248\tTrain acc: 0.703\tTest loss: 0.7442\tTest acc: 0.697\tTime: 6m 16s\n",
            "Epoch 14/20\tTrain loss: 0.7217\tTrain acc: 0.705\tTest loss: 0.7395\tTest acc: 0.701\tTime: 6m 17s\n",
            "Epoch 15/20\tTrain loss: 0.7144\tTrain acc: 0.707\tTest loss: 0.7438\tTest acc: 0.697\tTime: 6m 21s\n",
            "Epoch 16/20\tTrain loss: 0.7083\tTrain acc: 0.710\tTest loss: 0.7431\tTest acc: 0.700\tTime: 6m 17s\n",
            "Epoch 17/20\tTrain loss: 0.7020\tTrain acc: 0.711\tTest loss: 0.7395\tTest acc: 0.699\tTime: 6m 20s\n",
            "Epoch 18/20\tTrain loss: 0.6977\tTrain acc: 0.713\tTest loss: 0.7335\tTest acc: 0.700\tTime: 6m 18s\n",
            "Epoch 19/20\tTrain loss: 0.6940\tTrain acc: 0.716\tTest loss: 0.7394\tTest acc: 0.701\tTime: 6m 18s\n",
            "Epoch 20/20\tTrain loss: 0.6882\tTrain acc: 0.719\tTest loss: 0.7335\tTest acc: 0.704\tTime: 6m 18s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhSU1BS9FU2L"
      },
      "source": [
        "### Save the model weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1KJU9nL6M-W"
      },
      "source": [
        "## Save the weights\n",
        "torch.save(model.state_dict(), 'resnet18_tuned.pth')"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqVCNYtgFbex"
      },
      "source": [
        "del model"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqHC-2HikewS"
      },
      "source": [
        "## VGG-16-bn Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6jGvqyZLFXx"
      },
      "source": [
        "### Model architecture\n",
        "\n",
        "**Original paper**\n",
        "\n",
        "Very Deep Convolutional Netrowks for Large-Scale Image Recognition [(arXiv)](https://arxiv.org/abs/1409.1556)\n",
        "\n",
        "**The last layer**\n",
        "\n",
        "The last layer of VGG-16 model is called `classifier[6]`, with input size = `4096`\n",
        "\n",
        "We replace the last layer with a linear layer by `model.classifier[6] = nn.Linear(4096, NUM_OF_CLASSES, bias=True)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "def49d2d3caa4f6489614e80703a87dd",
            "3de3c6bcff0c4294b62e3af4435ba06e",
            "6286349560a44eec84827a53de9a8dd0",
            "d69676d8ca824584aa947b29be0aeb98",
            "c5cfef01062d4a98adce302099c45e4d",
            "d789aef464a74ea880669381dde042ad",
            "c25b3a3a17624d018c2ec01f8713f13d",
            "79f9026d2c5f470f8f42c9516330543e",
            "37a92a7709fc4c23a2bb8085f440a20a",
            "e8c40fee5ca94a189b7f292946315995",
            "936e1ed817014b5798a6da06b2cc4704"
          ]
        },
        "id": "2fA-s1x_LHkd",
        "outputId": "18346c49-89d7-499f-8a65-e5f7ea2d3fcf"
      },
      "source": [
        "## VGG-16 (bn) architecture\n",
        "model = models.vgg16_bn(pretrained=True)\n",
        "print(model)\n",
        "# count trainable parameters\n",
        "print(\"Number of trainable parameters: {}\".format(sum(param.numel() for param in model.parameters() if param.requires_grad)))\n",
        "# free the space\n",
        "del model"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "def49d2d3caa4f6489614e80703a87dd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/528M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n",
            "Number of trainable parameters: 138365992\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtpGtSGlh_A5"
      },
      "source": [
        "### Create transforms and dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KeRvmEMh_26",
        "outputId": "04039707-5104-4ff7-a03e-8484b5d7cac4"
      },
      "source": [
        "# create transform\n",
        "train_transform, test_transform = create_data_transforms(is_for_inception=False)\n",
        "\n",
        "# create dataset\n",
        "data_train = GalaxyZooDataset('class_labels_train_46183_C5.csv', 'images_train', train_transform)\n",
        "data_test = GalaxyZooDataset('class_labels_test_15395_C5.csv', 'images_test', test_transform)\n",
        "\n",
        "# dataloader\n",
        "train_loader = DataLoader(data_train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(data_test, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# check the sizes\n",
        "print(\"Number of training data: {} ({} batches)\".format(len(data_train), len(train_loader)))\n",
        "print(\"Number of testing data: {} ({} batches)\".format(len(data_test), len(test_loader)))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training data: 46183 (1444 batches)\n",
            "Number of testing data: 15395 (482 batches)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxtZn7pcidfG"
      },
      "source": [
        "### Train and fine-tune the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQmNL1Pqkabo",
        "outputId": "b50724a8-ec49-447d-caae-6fadc8b22afa"
      },
      "source": [
        "## Download the pre-trained VGG16 model\n",
        "model = models.vgg16_bn(pretrained=True)\n",
        "\n",
        "# freeze the weights\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# change the last fc layer\n",
        "model.classifier[6] = nn.Linear(4096, NUM_OF_CLASSES)\n",
        "print(model.classifier[6]) # print the modified last layer\n",
        "\n",
        "print(\"============\")\n",
        "print(\"Training the last layer only\")\n",
        "print(\"Number of trainable parameters: {}\".format(sum(param.numel() for param in model.parameters() if param.requires_grad)))\n",
        "print(\"============\")\n",
        "\n",
        "# move to gpu\n",
        "model = model.to(device)\n",
        "# loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "# scheduler\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
        "# train\n",
        "train_model(model, 5, criterion, optimizer, scheduler, print_every=1)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Fine tuning\n",
        "\"\"\"\n",
        "# unfreeze the weights of the last block\n",
        "for param in model.classifier[3].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "print(\"============\")\n",
        "print(\"Fine Tuning\")\n",
        "print(\"Number of trainable parameters: {}\".format(sum(param.numel() for param in model.parameters() if param.requires_grad)))\n",
        "print(\"============\")\n",
        "\n",
        "# move to gpu\n",
        "model = model.to(device)\n",
        "# loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
        "# scheduler\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
        "# train\n",
        "train_model(model, 20, criterion, optimizer, scheduler, print_every=1)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear(in_features=4096, out_features=5, bias=True)\n",
            "============\n",
            "Training the last layer only\n",
            "Number of trainable parameters: 20485\n",
            "============\n",
            "Epoch 1/5\tTrain loss: 1.0095\tTrain acc: 0.592\tTest loss: 0.9260\tTest acc: 0.622\tTime: 8m 41s\n",
            "Epoch 2/5\tTrain loss: 1.0078\tTrain acc: 0.592\tTest loss: 0.9219\tTest acc: 0.629\tTime: 8m 42s\n",
            "Epoch 3/5\tTrain loss: 0.9995\tTrain acc: 0.596\tTest loss: 0.9255\tTest acc: 0.617\tTime: 8m 42s\n",
            "Epoch 4/5\tTrain loss: 0.9918\tTrain acc: 0.599\tTest loss: 0.9149\tTest acc: 0.628\tTime: 8m 44s\n",
            "Epoch 5/5\tTrain loss: 0.9872\tTrain acc: 0.600\tTest loss: 0.9122\tTest acc: 0.631\tTime: 8m 43s\n",
            "============\n",
            "Fine Tuning\n",
            "Number of trainable parameters: 16801797\n",
            "============\n",
            "Epoch 1/20\tTrain loss: 0.9758\tTrain acc: 0.611\tTest loss: 0.9016\tTest acc: 0.631\tTime: 8m 43s\n",
            "Epoch 2/20\tTrain loss: 0.9184\tTrain acc: 0.628\tTest loss: 0.8754\tTest acc: 0.641\tTime: 8m 42s\n",
            "Epoch 3/20\tTrain loss: 0.9070\tTrain acc: 0.631\tTest loss: 0.8737\tTest acc: 0.643\tTime: 8m 42s\n",
            "Epoch 4/20\tTrain loss: 0.8978\tTrain acc: 0.633\tTest loss: 0.8634\tTest acc: 0.647\tTime: 8m 41s\n",
            "Epoch 5/20\tTrain loss: 0.8917\tTrain acc: 0.636\tTest loss: 0.8760\tTest acc: 0.643\tTime: 8m 41s\n",
            "Epoch 6/20\tTrain loss: 0.8873\tTrain acc: 0.637\tTest loss: 0.8631\tTest acc: 0.642\tTime: 8m 41s\n",
            "Epoch 7/20\tTrain loss: 0.8829\tTrain acc: 0.641\tTest loss: 0.8620\tTest acc: 0.647\tTime: 8m 41s\n",
            "Epoch 8/20\tTrain loss: 0.8791\tTrain acc: 0.639\tTest loss: 0.8596\tTest acc: 0.649\tTime: 8m 41s\n",
            "Epoch 9/20\tTrain loss: 0.8747\tTrain acc: 0.643\tTest loss: 0.8554\tTest acc: 0.649\tTime: 8m 42s\n",
            "Epoch 10/20\tTrain loss: 0.8732\tTrain acc: 0.642\tTest loss: 0.8593\tTest acc: 0.650\tTime: 8m 40s\n",
            "Epoch 11/20\tTrain loss: 0.8684\tTrain acc: 0.645\tTest loss: 0.8561\tTest acc: 0.652\tTime: 8m 37s\n",
            "Epoch 12/20\tTrain loss: 0.8640\tTrain acc: 0.646\tTest loss: 0.8533\tTest acc: 0.649\tTime: 8m 36s\n",
            "Epoch 13/20\tTrain loss: 0.8649\tTrain acc: 0.644\tTest loss: 0.8554\tTest acc: 0.655\tTime: 8m 35s\n",
            "Epoch 14/20\tTrain loss: 0.8588\tTrain acc: 0.648\tTest loss: 0.8578\tTest acc: 0.651\tTime: 8m 36s\n",
            "Epoch 15/20\tTrain loss: 0.8572\tTrain acc: 0.649\tTest loss: 0.8532\tTest acc: 0.652\tTime: 8m 35s\n",
            "Epoch 16/20\tTrain loss: 0.8542\tTrain acc: 0.651\tTest loss: 0.8525\tTest acc: 0.654\tTime: 8m 36s\n",
            "Epoch 17/20\tTrain loss: 0.8544\tTrain acc: 0.650\tTest loss: 0.8551\tTest acc: 0.652\tTime: 8m 37s\n",
            "Epoch 18/20\tTrain loss: 0.8518\tTrain acc: 0.653\tTest loss: 0.8483\tTest acc: 0.657\tTime: 8m 37s\n",
            "Epoch 19/20\tTrain loss: 0.8494\tTrain acc: 0.653\tTest loss: 0.8497\tTest acc: 0.657\tTime: 8m 37s\n",
            "Epoch 20/20\tTrain loss: 0.8494\tTrain acc: 0.652\tTest loss: 0.8519\tTest acc: 0.657\tTime: 8m 41s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3L79ayMikGC"
      },
      "source": [
        "### Save the model weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evh9GHywIfnS"
      },
      "source": [
        "## Save the weights\n",
        "torch.save(model.state_dict(), 'vgg16bn_tuned.pth')"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rajJx-V3mZQs"
      },
      "source": [
        "## Inception v3 Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TX5UGLpjVOE"
      },
      "source": [
        "### Model architecture\n",
        "\n",
        "**Original paper**\n",
        "\n",
        "Rethinking the Inception Architecture for Computer Vision [(arXiv)](https://arxiv.org/abs/1512.00567)\n",
        "\n",
        "**The last layer**\n",
        "\n",
        "The last layer of Inception v3 model is called `fc`, with input size = `2048`\n",
        "\n",
        "We replace the last layer with a linear layer by `model.fc = nn.Linear(2048, NUM_OF_CLASSES, bias=True)`\n",
        "\n",
        "**The auxiliary layer**\n",
        "\n",
        "In addition to the `fc` layer, the model has a second output layer `AuxLogits.fc`, with input size = `768`\n",
        "\n",
        "We replace the auxiliary layer with a linear layer by `model.AuxLogits.fc = nn.Linear(768, NUM_OF_CLASSES, bias=True)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36LNuYWsoUCk"
      },
      "source": [
        "## Inception v3 architecture\n",
        "model = models.inception_v3(pretrained=True)\n",
        "print(model)\n",
        "# count trainable parameters\n",
        "print(\"Number of trainable parameters: {}\".format(sum(param.numel() for param in model.parameters() if param.requires_grad)))\n",
        "# free the space\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JX8PFhKMjW8T"
      },
      "source": [
        "### Create transforms and dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLb1SKGmoj-i"
      },
      "source": [
        "# create transform\n",
        "train_transform, test_transform = create_data_transforms(is_for_inception=True)\n",
        "\n",
        "# create dataset\n",
        "data_train = GalaxyZooDataset('class_labels_train_46183_C5.csv', 'images_train', train_transform)\n",
        "data_test = GalaxyZooDataset('class_labels_test_15395_C5.csv', 'images_test', test_transform)\n",
        "\n",
        "# dataloader\n",
        "train_loader = DataLoader(data_train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(data_test, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# check the sizes\n",
        "print(\"Number of training data: {} ({} batches)\".format(len(data_train), len(train_loader)))\n",
        "print(\"Number of testing data: {} ({} batches)\".format(len(data_test), len(test_loader)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6cSoaRhjaWA"
      },
      "source": [
        "### Train and fine-tune the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeedY3mdo64W"
      },
      "source": [
        "## Download the pre-trained resnet18 model\n",
        "model = models.inception_v3(pretrained=True)\n",
        "\n",
        "# freeze the weights\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# change the last fc layer\n",
        "model.fc = nn.Linear(2048, NUM_OF_CLASSES, bias=True)\n",
        "print(model.fc) # print the modified last layer\n",
        "\n",
        "# change the aux fc layer\n",
        "model.AuxLogits.fc = nn.Linear(768, NUM_OF_CLASSES, bias=True)\n",
        "print(model.AuxLogits.fc) # print the modified aux fc layer\n",
        "\n",
        "print(\"============\")\n",
        "print(\"Training the last layer + aux layer\")\n",
        "print(\"Number of trainable parameters: {}\".format(sum(param.numel() for param in model.parameters() if param.requires_grad)))\n",
        "print(\"============\")\n",
        "\n",
        "# move to gpu\n",
        "model = model.to(device)\n",
        "# loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "# scheduler\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
        "# train\n",
        "train_model(model, 5, criterion, optimizer, scheduler, print_every=1, is_for_inception=True)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Fine tuning\n",
        "\"\"\"\n",
        "# unfreeze more weights\n",
        "for param in model.Mixed_7c.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "print(\"============\")\n",
        "print(\"Fine Tuning\")\n",
        "print(\"Number of trainable parameters: {}\".format(sum(param.numel() for param in model.parameters() if param.requires_grad)))\n",
        "print(\"============\")\n",
        "\n",
        "# move to gpu\n",
        "model = model.to(device)\n",
        "# loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
        "# scheduler\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
        "# train\n",
        "train_model(model, 20, criterion, optimizer, scheduler, print_every=1, is_for_inception=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjhenpf_jcgj"
      },
      "source": [
        "### Save the model weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8H4dfMbjWch"
      },
      "source": [
        "## Save the weights\n",
        "torch.save(model.state_dict(), 'inceptionv3_tuned.pth')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}